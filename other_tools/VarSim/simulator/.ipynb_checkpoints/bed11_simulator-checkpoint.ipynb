{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3791e93-c3b2-4b3d-840e-de8735b3f964",
   "metadata": {},
   "source": [
    "# Main input simulator \n",
    "\n",
    "This script simulates inputs for the read generator later\n",
    "- Inputs: \n",
    "    1. BED target file specifies locations of SNV of interest (hg19) \n",
    "    2. BED target region size \n",
    "    4. Fraction of tumor DNA in total (0.0 - 1.0) \n",
    "    5. Number of reads\n",
    "    6. Standard dev of log(coverage): this is because coverage in hybridcaputer sequencing is approximately log-normal \n",
    "    7. Read lengths\n",
    "\n",
    "\n",
    "- Output in the format:\n",
    "\n",
    "    #HAPLOTYPE_FRACTION:HAP1;HAP2;HAP3;HAP4\t0.5;0.3;0.1;0.1\n",
    "    \n",
    "    #CHROM\tPOSITION\tREF\tALT\tHAP1\tHAP2\tHAP3\tHAP4\tCOV\n",
    "    \n",
    "    chr1\t100000000\tA\tC,CCC,-\t0\t1\t2\t3\t1000\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "Notes: \n",
    "1. Allele freqs includes wild-type allele.\n",
    "2. Each location can have a different coverage (due to assay bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b5b0e8ab-22a9-417a-a576-8325d12c7d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import logging \n",
    "import sys \n",
    "import numpy as np \n",
    "\n",
    "logging.basicConfig(level=logging.DEBUG)\n",
    "\n",
    "def load_hap_fraction(hap_frac_str):\n",
    "    tmp = hap_frac_str.strip().split(\":\")[1].split('\\t')\n",
    "    labels = tmp[0].split(';')\n",
    "    values = tmp[1].split(';')\n",
    "    fracs = {}\n",
    "    for i in range(len(labels)):\n",
    "        fracs[labels[i]] = float(values[i])\n",
    "    return fracs\n",
    "\n",
    "def header_dict(header_list):\n",
    "    \"\"\"\n",
    "    Return a dict with the index of each header in the list\"\"\"\n",
    "    header_idx = {}\n",
    "    for i in range(len(header_list)):\n",
    "        header_idx[header_list[i]] = i\n",
    "    return header_idx\n",
    "\n",
    "def main_input_split(main_input_file, out_dir, noise=0.0):\n",
    "    \"\"\"\n",
    "    - Takes main input file, output directory, noise level (optional)\n",
    "    - Split into hap_gen_inputs accordingly\n",
    "    - For each hap, gives a number of read coverage (on average, they follow the HAPLOTYPE_FRACTION metric)\n",
    "    \"\"\"\n",
    "    # create output dir \n",
    "    try:\n",
    "        os.makedirs(out_dir)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    # read the fractions of haplotypes\n",
    "    for line in open(main_input_file, 'r'):\n",
    "        if line.startswith(\"#HAPLOTYPE_FRACTION\"):\n",
    "            fracs = load_hap_fraction(line)\n",
    "\n",
    "    # check to see if hap_input.txt files already exist, if so, remove them\n",
    "    hap_input_files = []\n",
    "    for hap in fracs:\n",
    "        f = out_dir +'/' + hap + '_input.txt'\n",
    "        if os.path.exists(f):\n",
    "            logging.info(\"Haplotype input file {} already exist. It will be replaced.\".format(f))\n",
    "            os.remove(f)\n",
    "        hap_input_files.append(f)\n",
    "\n",
    "    # read the REF + ALT alleles and assign the to each HAPLOTYPE\n",
    "    for line in open(main_input_file, 'r'):\n",
    "        if line.startswith('#CHROM'):\n",
    "            header = line.strip().replace(\"#\",'').split('\\t')\n",
    "            header_idx = header_dict(header)\n",
    "        elif line.startswith(\"#\") == False:\n",
    "            tmp = line.strip().split('\\t')\n",
    "            total_cov = int(tmp[header_idx['COV']])\n",
    "            ref = tmp[header_idx[\"REF\"]]\n",
    "            alt = tmp[header_idx[\"ALT\"]]\n",
    "            alleles = [ref] + alt.split(',')\n",
    "            #print(total_cov, ref, alt, alleles)\n",
    "            for hap in fracs:\n",
    "                fout = out_dir +'/' + hap+'_input.txt'\n",
    "                with open(fout, 'a') as f:\n",
    "                    line = tmp[:3]\n",
    "                    line += alleles[int(tmp[header_idx[hap]])]\n",
    "                    hap_cov = str(total_cov*fracs[hap]) * np.random.normal(loc=1.0, scale=noise)\n",
    "                    line += [hap_cov]\n",
    "                    f.write('\\t'.join(line)+'\\n')\n",
    "\n",
    "    return fracs, hap_input_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7f2b7367-4786-4404-add9-a56fb560992d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'HAP1': 0.5, 'HAP2': 0.3, 'HAP3': 0.1, 'HAP4': 0.1},\n",
       " ['./examples/HAP1_input.txt',\n",
       "  './examples/HAP2_input.txt',\n",
       "  './examples/HAP3_input.txt',\n",
       "  './examples/HAP4_input.txt'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mainInput = \"examples/main_input.txt\"\n",
    "out_dir = './examples'\n",
    "#for line in open(mainInput, 'r'):\n",
    "#    print(line)\n",
    "\n",
    "main_input_split(mainInput, out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0616e7e7-fb67-40a0-a3a2-850eb12e16a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HAP1': 0.5, 'HAP2': 0.3, 'HAP3': 0.1, 'HAP4': 0.1}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string = \"#HAPLOTYPE_FRACTION:HAP1;HAP2;HAP3;HAP4\t0.5;0.3;0.1;0.1\"\n",
    "load_hap_fraction(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "ea557171-9426-4a72-81d0-73e86cdd6339",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.normal(loc=1.0, scale=0.0, size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d2f2be-09e7-4ab3-97d1-d895eb294cad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base_kernel",
   "language": "python",
   "name": "base_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
